---
title: "realtime experiment"
author: "Dirk Ulbricht"
date: "Friday, February 13, 2015"
output: html_document
---

```{r}
# DirCode='C:/Users/Dirk/Documents/GitHub/bubblesbreakdowns'
DirCode='h:/Git/bubblesbreakdowns'

# sourcing necassary scripts for estimation and forecast (for a description see "olsbmalag.Rmd")
source(paste(DirCode,'/lag.exact.R',sep=''))
source(paste(DirCode,'/diff.R',sep=''))
source(paste(DirCode,'/chg.R',sep=''))
source(paste(DirCode,'/bmafo.R',sep=''))
source(paste(DirCode,'/olsbic3.R',sep=''))
source(paste(DirCode,'/olsbic1setgetting2.R',sep=''))
library("BMA")

# setting some values
horizon=3 # inflation is published with on month lag, but in the following, the variables
# are only lagged.
target='PCPIX' # core inflation
max.lag=12 # maximum lag length to be considered 
max.obs=120 # maximum number of past observations to be considered (rolling estimation);
# setting negative window turns that of (recursive estimation)
# rolling window size will be: max.obs-max.lag-horizon, as lags need to be considered for
# estimation. 

# loading realtime data sets and unrevised data 
load(paste(DirCode,'/data/sets.Rdata',sep=''))
df.unrevised=read.csv(paste(DirCode,'/data/unrevised data.csv'
                            ,sep='')
                      ,sep=','
                      ,na.strings='NaN'
                      ,row.names=1
                      )
overview.rt=read.csv(paste(DirCode,'/overview.csv',sep=''),row.names=1)
overview.nr=read.csv(paste(DirCode,'/data/NonrevData overview.csv',sep=''),sep=',')
overview.nr[,1]=gsub('-','.',overview.nr[,1])
# Saving a complete version of unrevised complete (necessary to get target variable without lags)
df.unrevised.compl=df.unrevised

# dropping the saisonally adjusted series for now
df.unrevised=df.unrevised[,-grep('.SA',colnames(df.unrevised))]
overview.nr=overview.nr[-grep('.SA',overview.nr[,1]),]

# dropping "MCOILWTICO" as it is too short (starting in 1986, first iteration here is 1983:7)
df.unrevised=df.unrevised[,-grep("MCOILWTICO",colnames(df.unrevised))]
overview.nr=overview.nr[-grep("MCOILWTICO",overview.nr[,1]),]


# getting bubble indicators

bubble.stock=read.csv(paste(DirCode,'/data/stockbubble.csv',sep=''),sep=';',row.names=1)
row.names(bubble.stock)=gsub('M',':',row.names(bubble.stock))
bubbletype=colnames(bubble.stock)
colnames(bubble.stock)=paste(colnames(bubble.stock),'stock',sep=' ')

bubble.housing=read.csv(paste(DirCode,'/data/Housingbubble.csv',sep=''),sep=';',row.names=1)
row.names(bubble.housing)=gsub('M',':',row.names(bubble.housing))
colnames(bubble.housing)=paste(colnames(bubble.housing),'house',sep=' ')


df.bubble=data.frame(matrix(NA,ncol=ncol(bubble.housing)+ncol(bubble.stock),nrow=nrow(df.unrevised)))
colnames(df.bubble)=c(colnames(bubble.housing),colnames(bubble.stock))
row.names(df.bubble)=row.names(df.unrevised)
df.bubble[row.names(bubble.stock),colnames(bubble.stock)]=bubble.stock
df.bubble[row.names(bubble.housing),colnames(bubble.housing)]=bubble.housing

# compound indicators
cc=complete.cases(df.bubble)
df.bubble=df.bubble[cc,]
df.bubble[,bubbletype]=NA
df.bubble[,bubbletype]=df.bubble[,colnames(bubble.housing)]+df.bubble[,colnames(bubble.stock)]

# transforming rownames (dates) of unrevised data accordingly
df.ur.rownames=row.names(df.unrevised)
dates=strsplit(df.ur.rownames,'\\.')
dates=sapply(dates,function(x) x[c(3,2)])
dates=apply(dates,2,function(x) paste(x,collapse=':'))
row.names(df.unrevised)=dates
```
Some of the variables that are not subject to data revisions are published with a publication lag nontheless.
```{r}

# make sure, the  right columns are addressed (same ordering in overview and df)
df.unrevised=df.unrevised[,as.character(overview.nr[,1])]
variables.tlag=overview.nr[overview.nr$Publication.Lag!=0,'Abbreviation']
for (var.tlag in variables.tlag){
        df.unrevised[,var.tlag]=lag.exact(df.unrevised[,var.tlag,drop=F]
                                          ,overview.nr[overview.nr$Abbr==var.tlag
                                                       ,'Publication.Lag'])
        }



# getting vintage dates that correspond to dates in rownames
vint.names=names(sets)
vint.last19=grep('99M12',vint.names)# last vintage of the 20th century
vint.dates=vint.names
vint.dates[1:vint.last19]=paste('19',vint.dates[1:vint.last19],sep='')
vint.dates[(vint.last19+1):length(vint.dates)]=paste('20',vint.dates[(vint.last19+1):length(vint.dates)],sep='')
vint.missing.zeros=grep('M[1-9]$',vint.dates)
# vint.dates[vint.missing.zeros]=paste('0',vint.dates[vint.missing.zeros],sep='')
vint.dates[vint.missing.zeros]=gsub('M',':0',vint.dates[vint.missing.zeros])
vint.dates=gsub('M',':',vint.dates)
vintage=data.frame(name=vint.names,date=vint.dates)

# dates in data matrices, both realtime and unrevised, must 
# at least contain vintages (observation 2015.1 not existing yet, but vintage 2015.1).
# If not a line needs to be added
aux.match=match(vintage$date,row.names(df.unrevised))
missing.dates=vintage$date[is.na(aux.match)]
missing.dates=as.character(missing.dates)
df.unrevised[missing.dates,]=NA

# are sets to short, too?
set.rt=sets[[193]]
aux.match=match(vintage$date,row.names(set.rt))
missing.dates=vintage$date[is.na(aux.match)]
missing.dates=as.character(missing.dates)
# add missing lines
sets=lapply(sets,function(x){x[missing.dates,]=NA
                             return(x)})

```

Each forecast origin, the set of unrevised data is shortened so that it includes only that observations that had been available up to then.
The set of realtime and unrevised data are combined.
For each variable in the set, 1st and 2nd differences, month-on-month and year-on-year change rates are computed and added. The each of the sets is used to estimate the different models and to compute the 12 month-horizon forecasts.
```{r}
# loop -----------------------------------------------------------

push.down=function(variable,set){
        # pushes all variables to the forecast origin 
        aux=set[,variable]
        naux=length(aux)
        values=aux[is.na(aux)==F]
        nvalues=length(values)
        aux2=rep(NA,naux)
        aux2[(naux-nvalues+1):naux]=values
        return(aux2)
        }
forecast.all=vector('list',length(sets))

extract.ar=c('fc','horizon','nobs','msr','p1','names')
extract=c('fc','horizon','nobs','msr','p1','p2','names')

for (vint.num in 1:length(sets)){# vint.num=1
        set.rt=sets[[vint.num]]
        set.last.date=vintage[
                grep(paste(vintage$name[vint.num],'$',sep=''),vintage$name)
                # $ is needed to get exactly the vintage required. 
                # 1998M1 and not 1998M10,1998M11, 1998M12
                ,'date']
        set.lst.obs=grep(set.last.date,row.names(set.rt))
        set.rt=set.rt[1:set.lst.obs,]
        set.unrevised=df.unrevised[row.names(set.rt),]
        set=cbind(set.rt,set.unrevised)
        
        # Rossi and Sekhposyan (2008) targets
        y.raw=set[,target,drop=F]
        col.target=which(colnames(set)==target)
        set=set[,-col.target]
        rm(col.target)
        y=1200/horizon*log(y.raw/lag.exact(y.raw,horizon))
        yx=1200*log(y.raw/lag.exact(y.raw,1))
        colnames(yx)=paste(target,'x',sep='')
        #         if (target=='PCPIX'){# Rossi and Sekhposyan (2008) inflation target
        #                 y=y-yx
        #                 }
        
        # filtering those variables that cannot be transformed to change rates
        # due to zeros.#### attention: this might lead to an unbalanced panel!
        set.aux=set
        set.aux[is.na(set)]=1 # NAs to 1, they are no problem for computing chg-rates
        chg.ok=colSums(set.aux<=0)==0
        
        # adding transformations
        set=cbind(set,diff(set,1,1)
                  ,diff(set,2,1)
                  ,chg(set[,chg.ok],1)
                  ,chg(set[,chg.ok],12)
                  )
        
        # adding bubble indicator
        set=cbind(set,df.bubble[row.names(set),])
        
        # window of max.obs month back
        if (max.obs>0){
                y=y[(nrow(set)-max.obs+1):nrow(set),1,drop=F]
                yx=yx[(nrow(set)-max.obs+1):nrow(set),1,drop=F]
                set=set[(nrow(set)-max.obs+1):nrow(set),]
                }
        
        # pushing down all variables        
        variables=colnames(set)
        dates=row.names(set)
        
        y[,1]=push.down(target,y)
        yx[,1]=push.down(paste(target,'x',sep=''),yx)
        
        set=data.frame(sapply(variables,push.down,set))
        row.names(set)=dates
        
        forecast=data.frame(matrix(NA,nrow=ncol(set)+1,length(extract)))
        colnames(forecast)=extract
        row.names(forecast)=c('ar',colnames(set))
        
        forecast['ar',extract.ar]=unlist(
                olsbic3(y,yx,horizon,max.lag)[extract]
                )
        p1=forecast['ar','p1']       
        for (i in 1:ncol(set)){# i=1
                xx=cbind(yx,set[,i,drop=F])
                resu=unlist(
                        olsbic1setgetting2(y,xx,horizon,max.lag,p1=p1)[extract]
                        )
                if (length(resu)>0){
                     forecast[colnames(set)[i],extract]=resu   
                }
                
                }# end model loop
        forecast.all[[vint.num]]=forecast
        
        }#end vintage loop
save(forecast.all,file=paste(DirCode,'/results/',target,'_h',horizon,'.RData',sep=''))
```





